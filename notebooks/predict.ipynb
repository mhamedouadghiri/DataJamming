{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pickle\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, LSTM, Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"../input/pfa-files/pickledInfo.pickle\", \"rb\") as pickle_file:\n    info = pickle.load(pickle_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model(\"../input/pfa-files/xor_v3.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_token_index = info[\"input_token_index\"]\ntarget_token_index = info[\"target_token_index\"]\nnum_encoder_tokens = info[\"num_encoder_tokens\"]\nnum_decoder_tokens = info[\"num_decoder_tokens\"]\nmax_encoder_seq_length = info[\"max_encoder_seq_length\"]\nmax_decoder_seq_length = info[\"max_decoder_seq_length\"]\nlatent_dim = info[\"latent_dim\"]\n#dropout_rate = info[\"dropout_rate\"]\ndropout_rate = 0.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict((i, char) for char, i in target_token_index.items())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_inputs = model.input[0]   # input_1\nencoder_outputs, state_h_enc, state_c_enc = model.layers[2].output   # lstm_1\nencoder_states = [state_h_enc, state_c_enc]\nencoder_model = Model(encoder_inputs, encoder_states)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder_inputs = model.input[1]   # input_2\ndecoder_state_input_h = Input(shape=(latent_dim,), name='input_3')\ndecoder_state_input_c = Input(shape=(latent_dim,), name='input_4')\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\ndecoder_lstm = model.layers[3]\ndecoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n    decoder_inputs, initial_state=decoder_states_inputs)\ndecoder_states = [state_h_dec, state_c_dec]\ndecoder_dense = model.layers[4]\ndecoder_outputs = decoder_dense(decoder_outputs)\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs] + decoder_states)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0, target_token_index['\\t']] = 1.\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict(\n            [target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += sampled_char\n\n        # Exit condition: either hit max length\n        # or find stop character.\n        if (sampled_char == '\\n' or\n           len(decoded_sentence) > max_decoder_seq_length):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1, 1, num_decoder_tokens))\n        target_seq[0, 0, sampled_token_index] = 1.\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the message to decrypt\ninput_text = \")Ä€\u0014 W]\"\n\nencoder_input_data = np.zeros(\n    (1, max_encoder_seq_length, num_encoder_tokens),\n    dtype='float32')\n\nfor t, char in enumerate(input_text):\n    encoder_input_data[0, t, input_token_index[char]] = 1.\n#encoder_input_data[0, t + 1:, input_token_index[' ']] = 1.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_seq = encoder_input_data[0:1]\ndecoded_sentence = decode_sequence(input_seq)\nprint(\"Message to decrypt:\", input_text)\nprint(\"Decrypted message:\", decoded_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}