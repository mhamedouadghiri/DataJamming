{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "file_to_crypt = \"\"\n",
    "file_crypted = \"\"\n",
    "\n",
    "with open(\"files/\" + file_to_crypt, 'r', encoding='utf-8') as f:\n",
    "    text = f.readlines()\n",
    "\n",
    "with open(\"files/\" + file_crypted, 'r', encoding='utf-8') as f:\n",
    "    text_encrypted = f.readlines()\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001\n",
      "10001\n"
     ]
    }
   ],
   "source": [
    "print(len(text))\n",
    "print(len(text_encrypted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# to store the samples\n",
    "en_samples = []\n",
    "de_samples = []\n",
    "\n",
    "# to store the characters\n",
    "en_chars = set()\n",
    "de_chars = set()\n",
    "\n",
    "# TODO..? cleanup..\n",
    "# sanity check for next fori\n",
    "assert len(text) == len(text_encrypted)\n",
    "\n",
    "# split the samples and get the character sets\n",
    "for i in range(len(text)):\n",
    "    en_ = text_encrypted[i]\n",
    "    de_ = text[i]\n",
    "    de_ = '\\t' + de_\n",
    "    for char in de_:\n",
    "        if char not in de_chars:\n",
    "            de_chars.add(char)\n",
    "    for char in en_:\n",
    "        if char not in en_chars:\n",
    "            en_chars.add(char)\n",
    "    en_samples.append(en_)\n",
    "    de_samples.append(de_)\n",
    "\n",
    "de_chars.add('\\n')\n",
    "de_chars.add('\\t')\n",
    "\n",
    "en_chars.add('\\n')\n",
    "en_chars.add('\\t')\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# chars <-> ints convert\n",
    "\n",
    "de_char_to_int = dict()\n",
    "de_int_to_char = dict()\n",
    "en_char_to_int = dict()\n",
    "en_int_to_char = dict()\n",
    "\n",
    "for i, char in enumerate(de_chars):\n",
    "    de_char_to_int[char] = i\n",
    "    de_int_to_char[i] = char\n",
    "    \n",
    "for i, char in enumerate(en_chars):    \n",
    "    en_char_to_int[char] = i\n",
    "    en_int_to_char[i] = char\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# get lengths and sizes\n",
    "num_en_chars = len(en_chars)\n",
    "num_de_chars = len(de_chars)\n",
    "\n",
    "max_en_chars_per_sample = max([len(sample) for sample in en_samples])\n",
    "max_de_chars_per_sample = max([len(sample) for sample in de_samples])\n",
    "\n",
    "num_en_samples = len(en_samples)\n",
    "num_de_samples = len(de_samples)\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# initiate numpy arrays to hold the data for the seq2seq model\n",
    "encoder_input_data = np.zeros((num_en_samples,\n",
    "                               max_en_chars_per_sample,\n",
    "                               num_en_chars),\n",
    "                              dtype='float32')\n",
    "\n",
    "decoder_input_data = np.zeros((num_de_samples,\n",
    "                               max_de_chars_per_sample,\n",
    "                               num_de_chars),\n",
    "                              dtype='float32')\n",
    "\n",
    "target_data = np.zeros((num_de_samples,\n",
    "                       max_de_chars_per_sample,\n",
    "                       num_de_chars),\n",
    "                      dtype='float32')\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# one-hot encode\n",
    "# takes too much space, thus 1/4 of original file\n",
    "# TODO.. next step: use embedding, words instead of chars\n",
    "for i, (en_sample, de_sample) in enumerate(zip(en_samples, de_samples)):\n",
    "    for char, en_char in enumerate(en_sample):\n",
    "        encoder_input_data[i, char, en_char_to_int[en_char]] = 1\n",
    "    for char, de_char in enumerate(de_sample):\n",
    "        decoder_input_data[i, char, de_char_to_int[de_char]] = 1\n",
    "        if char > 0 :\n",
    "            target_data[i, char - 1, de_char_to_int[de_char]]  = 1\n",
    "            \n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################################################################################################\n",
    "# #################################################################################################\n",
    "# #################################################################################################\n",
    "\n",
    "# END TWDS NLP1 P1\n",
    "\n",
    "# START TWDS NLP1 P2 / NLP2 ?\n",
    "\n",
    "# #################################################################################################\n",
    "# #################################################################################################\n",
    "# #################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANUP. OR IS IT?.. SHOULD RECONSIDER\n",
    "\n",
    "import string, re\n",
    "from string import digits\n",
    "\n",
    "# Convert text to lowercase :\n",
    "text_encrypted=list(map(lambda x: x.lower(), text_encrypted))\n",
    "text=list(map(lambda x: x.lower(), text))\n",
    "\n",
    "# Process commas :\n",
    "text_encrypted=list(map(lambda x: re.sub(\"'\", '', x), text_encrypted))\n",
    "text_encrypted=list(map(lambda x: re.sub(\",\", ' COMMA', x), text_encrypted))\n",
    "\n",
    "text=list(map(lambda x: re.sub(\"'\", '', x), text))\n",
    "text=list(map(lambda x: re.sub(\",\", ' COMMA', x),text))\n",
    "\n",
    "# Getting rid of punctuation\n",
    "exclude = set(string.punctuation)\n",
    "text_encrypted=list(map(lambda x: ''.join(ch for ch in x if ch not in exclude), text_encrypted))\n",
    "text=list(map(lambda x: ''.join(ch for ch in x if ch not in exclude), text))\n",
    "\n",
    "# Getting rid of digits\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "text_encrypted=list(map(lambda x: x.translate(remove_digits), text_encrypted))\n",
    "text=list(map(lambda x: x.translate(remove_digits), text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Processing\n",
    "\n",
    "# Appending SOS andEOS to target data\n",
    "text = list(map(lambda x : 'SOS_ '+ x + ' _EOS', text))\n",
    "\n",
    "# Create word dictionaries\n",
    "en_words=set()\n",
    "for line in text_encrypted:\n",
    "    for word in line.split():\n",
    "        if word not in en_words:\n",
    "            en_words.add(word)\n",
    "    \n",
    "de_words=set()\n",
    "for line in text:\n",
    "    for word in line.split():\n",
    "        if word not in de_words:\n",
    "            de_words.add(word)\n",
    "            \n",
    "# get lengths and sizes\n",
    "num_en_words = len(en_words)\n",
    "num_de_words = len(de_words)\n",
    "\n",
    "max_en_words_per_sample = max([len(sample.split()) for sample in text_encrypted])+5\n",
    "max_de_words_per_sample = max([len(sample.split()) for sample in text])+5\n",
    "\n",
    "num_en_samples = len(text_encrypted)\n",
    "num_de_samples = len(text)\n",
    "\n",
    "# Get lists of words\n",
    "input_words = sorted(list(en_words))\n",
    "target_words = sorted(list(de_words))\n",
    "\n",
    "en_token_to_int = dict()\n",
    "en_int_to_token = dict()\n",
    "\n",
    "de_token_to_int = dict()\n",
    "de_int_to_token = dict()\n",
    "\n",
    "#Tokenizing the words ( Convert them to numbers )\n",
    "for i,token in enumerate(input_words):\n",
    "    en_token_to_int[token] = i\n",
    "    en_int_to_token[i]     = token\n",
    "\n",
    "for i,token in enumerate(target_words):\n",
    "    de_token_to_int[token] = i\n",
    "    de_int_to_token[i]     = token\n",
    "\n",
    "# initiate numpy arrays to hold the data that our seq2seq model will use\n",
    "encoder_input_data = np.zeros(\n",
    "    (num_en_samples, max_en_words_per_sample),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (num_de_samples, max_de_words_per_sample),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (num_de_samples, max_de_words_per_sample, num_de_words),\n",
    "    dtype='float32')\n",
    "\n",
    "# Process samples, to get input, output, target data\n",
    "for i, (input_text, target_text) in enumerate(zip(text_encrypted, text)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t] = en_token_to_int[word]\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = de_token_to_int[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character\n",
    "            decoder_target_data[i, t - 1, de_token_to_int[word]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO.. cleanup!!!!\n",
    "\n",
    "# Importing needed dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Input, Embedding, TimeDistributed, Flatten, Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some constants: \n",
    "vec_len       = 300   # Length of the vector that we willl get from the embedding layer\n",
    "latent_dim    = 1024  # Hidden layers dimension \n",
    "dropout_rate  = 0.2   # Rate of the dropout layers\n",
    "batch_size    = 64    # Batch size\n",
    "epochs        = 30    # Number of epochs\n",
    "\n",
    "# TODO params tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\mhamed\\venvpfa\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it\n",
    "# Input layer of the encoder\n",
    "encoder_input = Input(shape=(None,))\n",
    "\n",
    "# Hidden layers of the encoder\n",
    "encoder_embedding = Embedding(input_dim = num_en_words, output_dim = vec_len)(encoder_input)\n",
    "encoder_dropout   = (TimeDistributed(Dropout(rate = dropout_rate)))(encoder_embedding)\n",
    "encoder_LSTM      = LSTM(latent_dim, return_sequences=True)(encoder_dropout)\n",
    "\n",
    "# Output layer of the encoder\n",
    "encoder_LSTM2_layer = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_LSTM2_layer(encoder_LSTM)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state\n",
    "# Input layer of the decoder\n",
    "decoder_input = Input(shape=(None,))\n",
    "\n",
    "# Hidden layers of the decoder\n",
    "decoder_embedding_layer = Embedding(input_dim = num_de_words, output_dim = vec_len)\n",
    "decoder_embedding = decoder_embedding_layer(decoder_input)\n",
    "\n",
    "decoder_dropout_layer = (TimeDistributed(Dropout(rate = dropout_rate)))\n",
    "decoder_dropout = decoder_dropout_layer(decoder_embedding)\n",
    "\n",
    "decoder_LSTM_layer = LSTM(latent_dim, return_sequences=True)\n",
    "decoder_LSTM = decoder_LSTM_layer(decoder_dropout, initial_state = encoder_states)\n",
    "\n",
    "decoder_LSTM_2_layer = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_LSTM_2,_,_ = decoder_LSTM_2_layer(decoder_LSTM)\n",
    "\n",
    "# Output layer of the decoder\n",
    "decoder_dense = Dense(num_de_words, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_LSTM_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_input, decoder_input], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    3450300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 300)    1711500     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 1024)   5427200     time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 300)    0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 1024), (None 8392704     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, None, 1024)   5427200     time_distributed_2[0][0]         \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 1024), 8392704     lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 5705)   5847625     lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 38,649,233\n",
      "Trainable params: 38,649,233\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.callbacks import EarlyStopping\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\mhamed\\venvpfa\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\mhamed\\venvpfa\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 9200 samples, validate on 801 samples\n",
      "Epoch 1/30\n",
      "9200/9200 [==============================] - 1116s 121ms/step - loss: 1.6283 - accuracy: 0.0925 - val_loss: 1.7689 - val_accuracy: 0.1143\n",
      "Epoch 2/30\n",
      "  64/9200 [..............................] - ETA: 18:52 - loss: 1.4920 - accuracy: 0.1335"
     ]
    }
   ],
   "source": [
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.08,\n",
    "          callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
